[
	{
		"role": "user",
		"content": "Generate a podcast record with a transcription",
		"app": "podcasts",
		"id": "5f9wch",
		"timestamp": 1731777816797
	},
	{
		"role": "assistant",
		"content": "Podcast Uploaded [Listen Here](https://assistant-assets.nickgriffin.uk/podcasts/0.rc71krp9ep/recording.mp3)",
		"name": "podcast_upload",
		"data": {
			"url": "https://assistant-assets.nickgriffin.uk/podcasts/0.rc71krp9ep/recording.mp3"
		},
		"id": "sl1vyn",
		"timestamp": 1731777816963
	},
	{
		"role": "assistant",
		"name": "podcast_transcribe",
		"content": "Podcast Transcribed: 0rnvr7krqdrgp0ck6r09dk4f90",
		"data": {
			"id": "0rnvr7krqdrgp0ck6r09dk4f90",
			"model": "thomasmol/whisper-diarization",
			"version": "cbd15da9f839c5f932742f86ce7def3a03c22e2b4171d42823e83e314547003f",
			"input": {
				"file": "https://assistant-assets.nickgriffin.uk/podcasts/0.rc71krp9ep/recording.mp3",
				"group_segments": true,
				"language": "en",
				"num_speakers": 2,
				"offset_seconds": 0,
				"prompt": "LLama, AI, Meta",
				"transcript_output_format": "segments_only",
				"translate": false
			},
			"logs": "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\nbuilt with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\nconfiguration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\nlibavutil      56. 70.100 / 56. 70.100\nlibavcodec     58.134.100 / 58.134.100\nlibavformat    58. 76.100 / 58. 76.100\nlibavdevice    58. 13.100 / 58. 13.100\nlibavfilter     7.110.100 /  7.110.100\nlibswscale      5.  9.100 /  5.  9.100\nlibswresample   3.  9.100 /  3.  9.100\nlibpostproc    55.  9.100 / 55.  9.100\n[mp3 @ 0x558b810fa6c0] Skipping 921 bytes of junk at 0.\n[mp3 @ 0x558b810fa6c0] Estimating duration from bitrate, this may be inaccurate\nInput #0, mp3, from '/tmp/tmpg6kqcpverecording.mp3':\nDuration: 00:25:07.40, start: 0.000000, bitrate: 192 kb/s\nStream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 192 kb/s\nStream mapping:\nStream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to 'temp-1731777822608914252.wav':\nMetadata:\nISFT            : Lavf58.76.100\nStream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\nMetadata:\nencoder         : Lavc58.134.100 pcm_s16le\nsize=       1kB time=00:00:00.00 bitrate=N/A speed=N/A\nsize=   13312kB time=00:07:13.65 bitrate= 251.5kbits/s speed= 867x\nsize=   27136kB time=00:14:30.42 bitrate= 255.4kbits/s speed= 870x\nsize=   40704kB time=00:21:47.53 bitrate= 255.0kbits/s speed= 872x\n[mp3float @ 0x558b810fccc0] Header missing\nError while decoding stream #0:0: Invalid data found when processing input\nsize=   47106kB time=00:25:07.39 bitrate= 256.0kbits/s speed= 874x\nvideo:0kB audio:47106kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000162%\nStarting transcribing\nFinished with transcribing, took 111.51 seconds\nStarting diarization\nFinished with diarization, took 19.141 seconds\nStarting merging\nFinished with merging, took 0.0033207 seconds\nStarting cleaning\nFinished with cleaning, took 0.00024724 seconds\nProcessing time: 130.65 seconds\ndone with inference\n",
			"output": {
				"language": "en",
				"num_speakers": 2,
				"segments": [
					{
						"avg_logprob": -0.16096697522784179,
						"end": 21.75,
						"speaker": "SPEAKER_00",
						"start": 2.7,
						"text": "Let me ask you about AI. It seems like this year, for the entirety of the human civilization, is an interesting year for the development of artificial intelligence. A lot of interesting stuff is happening. So Meta is a big part of that. Meta has developed LLama, which is a 65 billion parameter model."
					},
					{
						"avg_logprob": -0.16096697522784179,
						"end": 38.81,
						"speaker": "SPEAKER_00",
						"start": 24.09,
						"text": "There's a lot of interesting questions I can ask here, one of which has to do with open source. But first, can you tell the story of developing of this model and making the complicated decision of how to release it?"
					},
					{
						"avg_logprob": -0.14789604609555537,
						"end": 255.27,
						"speaker": "SPEAKER_01",
						"start": 39.49,
						"text": "Yeah, sure. I think you're right, first of all, that in the last year, there have been a bunch of advances on scaling up these large transformer models. So there's the language equivalent of it with large language models. There's sort of the image generation equivalent with these large diffusion models. And there's a lot of fundamental research that's gone into this. And Meta has taken the approach of being quite open and academic in our development of AI. Part of this is we want to have the best people in the world researching this. And a lot of the best people want to know that they're going to be able to share their work. So that's part of the deal that we have is that we can get, if you're one of the top AI researchers in the world and come here, you can get access to kind of industry scale infrastructure. And part of our ethos is that we want to share what's invented broadly. We do that with a lot of the different AI tools that we create. And Lama is the language model that our research team made. And we did a limited open source release for it, which was intended for, researchers to be able to use it. But responsibility and getting safety right on these is very important. So we didn't think that for the first one, there were a bunch of questions around whether we should be releasing this commercially. So we kind of punted on that for V1 of Lama and just released it from research. Now, obviously by releasing it for research, it's out there, but companies know that they're not supposed to kind of put it into commercial release. And we're working on the follow-up models for this and thinking through how exactly this should work for follow-on now that we've had time to work on a lot more of the safety and the pieces around that. But overall, I mean, this is, I just kind of think that it would be good there were a lot of different folks who had the ability to build state-of-the-art, technology here in not just a small number of big companies. Where to train one of these AI models, the state-of-the-art models is just takes hundreds of millions of dollars of infrastructure, right? So there are not that many organizations in the world that can do that at the biggest scale today. And now it gets more efficient every day. So I do think that that will be available to more and more people. More folks over time. But I just think like there's all this innovation out there that people can create. And I just think that we'll also learn a lot by seeing what the whole community of students and hackers and startups and different folks build with this. And that's kind of been how we've approached this. And it's also how we've done a lot of our infrastructure. And we took our whole data center design and our server design and we built this open compute project where we just made that public. And part of the theory was like, all right, if we make it so that more people can use this server design, then that'll enable more innovation. It'll also make the server design more efficient and that'll make our business more efficient too. So that's worked. And we've just done this with a lot of our infrastructure."
					},
					{
						"avg_logprob": -0.24943276754645413,
						"end": 322.73,
						"speaker": "SPEAKER_00",
						"start": 256.13,
						"text": "So for people who don't know, you did the limited release, I think in February of this year of Lama. And it got quote unquote leaked, meaning like it's, it escaped the, the, the limited release aspect, but it was, you know, that something you probably anticipated given that it's just released to researchers. We shared it with researchers. It's just trying to make sure that there's like a slow release. Yeah. But from there, I just would love to get your comment on what happened next, which is like, there's a very vibrant open source community that just built stuff on top of it. There's a Lama CPP. Basically, there's stuff that makes it more efficient to run on smaller computers. There's combining with reinforcement learning with human feedback. So some of the different interesting fine tuning mechanisms, there's then also like fine tuning in a GPT three generations. There's a lot of GPT for all, Alpaca, Colossal AI, all these kinds of models just kind of spring up, like run on top of it. What do you think of that?"
					},
					{
						"avg_logprob": -0.28684701514777855,
						"end": 520.64,
						"speaker": "SPEAKER_01",
						"start": 323.03,
						"text": "No, I think it's been really neat to see. I mean, there's been folks who are getting it to run on. Local devices, right? So if you're an individual who just wants to experiment with this at home, you probably don't have a large budget to get access to a large amount of cloud compute. So getting it to run on your local laptop is pretty good. Right. And pretty relevant. And then there are things like Lama CPP, re-implemented it more efficiently. So now even when we run our own versions of it, we can do it on way less compute and it just way more efficient. Save a lot of money for everyone who uses this. So that is good. I do think it's worth calling out that because this was a relatively early release, Lama isn't quite as on the frontier as, for example, the biggest open AI models or the biggest Google models. Right. And you mentioned that the largest Lama model that we released had 65 billion parameters. And when no one knows, you know, I guess outside of open AI exactly what the specs are for GPT-4, but I think the, you know, my understanding is it's like 10 times bigger. And I think Google's Palm model is also, I think has about 10 times as many parameters. Now, the Lama models are very efficient, so they perform well for something that's around 65 billion parameters. So for me, that was also part of this because there's this whole debate around, you know, is it good for? Everyone in the world to have access to, to the most frontier AI models. And I think as the AI models start approaching something that's like a super human intelligence, that's a bigger question that we'll have to grapple with. But right now, I mean, these are still very basic tools. They're, you know, they're, they're powerful in the sense that, you know, a lot of open source software like databases or web servers can enable. A lot of pretty important things, but I don't think anyone looks at the, the, you know, the current generation of Lama and thinks it's, you know, anywhere near a super intelligence. So I think that a bunch of those questions around like, is it, is it good to, to kind of get out there? I think at this stage, surely you, you want more researchers working on it for all the reasons that, that open source software has a lot of advantages. And we talked about efficiency before, but another one is just open source software tends to be. More secure because you have more people looking at it openly and scrutinizing it and finding holes in it. And that makes it more safe. So I think at this point it's more, I think it's generally agreed upon that open source software is generally more secure and safer than things that are kind of developed in a silo where people try to get through security through obscurity. So like that for the scale of, of, of what we're seeing now with AI, I think we're more likely to get to. You know, good alignment and good, um, understanding of, of, of kind of what needs to do to make this work well by having it be open source. And, and that's something that I think is, is quite good to have out there and, and, and happening publicly at this point."
					},
					{
						"avg_logprob": -0.18647203319951108,
						"end": 577.88,
						"speaker": "SPEAKER_00",
						"start": 520.74,
						"text": "Matt, I've released a lot of models as open source. So, uh, the massively multi lingual speech model, the image model, that's, I mean, I'll, I'll ask you questions about those, but the point is, uh, you've open sourced quite a lot. You've been spearheading the open source movement. Where's, um, that's really positive, inspiring to see from one angle, from the research angle, of course, there's folks who are really terrified about the existential threat of artificial intelligence and those folks will say that, you know, um, you have to be careful about the open sourcing, uh, step, but what, where do you see the future of open source here, uh, as part of Meta, the tension here is, do you want to release the magic sauce? That's one tension. And the other one is, uh, do you want to put a powerful tool in the hands of, uh, bad actors, even though it probably has a huge amount of positive impact also."
					},
					{
						"avg_logprob": -0.19548611530551205,
						"end": 700.64,
						"speaker": "SPEAKER_01",
						"start": 578.8,
						"text": "Yeah. I mean, again, I think for the stage that we're at in the development of AI, I don't think anyone looks at the current state of things and thinks that this is super intelligence. Um, and you know, the models that we're talking about for the llama models here are, you know, generally an order of magnitude smaller than what open AI or Google has. Um, and you know, the models that we're talking about for the llama models here are, you know, generally an order of magnitude smaller than what open AI or Google has. So I think that at least for the stage that we're at now, the equity is balanced strongly in my view towards doing this more openly. Um, I think if you got something that was closer to super intelligence, then I think you'd have to discuss that more and think through that, um, a lot more. And we haven't made a decision yet as to what we would do if we were in that position, but I don't think, I think there's a good chance that we're pretty far off from that position. So, um, so. I, I'm, I'm not, uh, I'm certainly not saying that the position that we're taking on this now applies to every single thing that we would ever do. And, you know, certainly inside the company, you know, we probably do more open source work than, you know, most of the other big tech companies, but we also don't open source everything, right? And a lot of our, you know, the core kind of app code for WhatsApp or Instagram or something, I mean, we're not open sourcing that. It's not like a, a general enough piece of software that would be useful for a lot of people to do. Um, you know, whereas the software that we do, whether it's like a, an open source server design or, um, or basically, you know, things like Memcache, right? Like a, a good, you know, it was, it was probably our earliest project, um, that, that I worked on. It was probably one of the last things that I, that I coded and, and, and led directly for the company. Um, but, but basically there's like caching tool, um, for, for quick David data retrieval. Um, these are things that. That are just broadly useful across like anything that you want to build. And, and I think that some of the language models now have that feel as well as some of the other things that we're building, like the translation tool that, that you just referenced."
					},
					{
						"avg_logprob": -0.13071165640814966,
						"end": 724.78,
						"speaker": "SPEAKER_00",
						"start": 700.9,
						"text": "So text to speech and speech to text, you've expanded it from around a hundred languages to more than 1100 languages. And you can identify more than the model can identify more than 4,000 spoken languages, which is 40 times more than any known previous technology to me. That's really, really, really exciting in terms of connecting the world, breaking down barriers that language creates. Yeah."
					},
					{
						"avg_logprob": -0.1536227812809227,
						"end": 751.73,
						"speaker": "SPEAKER_01",
						"start": 724.84,
						"text": "I think being able to translate between all of these different pieces in real time, this has been a kind of common sci-fi idea that we'd all have, you know, whether it's, I don't know, an earbud or glasses or something that can help translate in real time, um, between all these different languages. And that's one that I think technology is basically delivering. Now, so I think, yeah, I think that's pretty, pretty exciting."
					},
					{
						"avg_logprob": -0.13200000715255739,
						"end": 764.17,
						"speaker": "SPEAKER_00",
						"start": 752.11,
						"text": "Uh, you mentioned the next version of Lama. What can you say about the next version of Lama? What, what, what can you say about like what, uh, what were you working on in terms of release in terms of the vision for that?"
					},
					{
						"avg_logprob": -0.13200000715255739,
						"end": 888.65,
						"speaker": "SPEAKER_01",
						"start": 764.71,
						"text": "Well, a lot of what we're doing is taking the first version, which was primarily, you know, this research version and trying to now build a version that has all of the latest state of the art. Safety precautions built in, um, and, and we're, um, we're using some more data to train it, um, from across our services, but, but a lot of the, the work that we're doing internally is really just focused on making sure that this is, um, you know, as aligned and responsible as, as possible. And, you know, we're building a lot of our own, you know, we're talking about kind of the open source infrastructure, but, you know, the, the main thing that we focus on building. Here, you know, a lot of product experiences to help people connect and express themselves. So, you know, we're going to, I've, I've talked about a bunch of this stuff, but, um, then you'll have, you know, an assistant that you can talk to in WhatsApp. Um, you know, I think, I think in the future, every creator will, will have kind of an AI agent that can kind of act on their behalf that their fans can talk to. I, I want to get to the point where every small business basically has an AI agent that people can talk to for, you know, to do commerce and customer support. And things like that. So there are going to be all these different things and Lama or the language model underlying this is, is basically going to be the engine that powers that the reason to open source it is that, um, as, as we did with, um, with the, the first version is that it, uh, you know, basically it, it unlocks a lot of innovation in the ecosystem. We'll, we'll make our products better as well. Um, and also gives us a lot of valuable feedback on security and safety, which is important. But yeah, I mean, the, the, the work that we're doing to advance the infrastructure, it's, um, it's basically at this point, taking it beyond a research project into something which is ready to be kind of core infrastructure, not only for our own products, but, um, you know, hopefully for, for a lot of other things out there too."
					},
					{
						"avg_logprob": -0.11641270365596802,
						"end": 900.99,
						"speaker": "SPEAKER_00",
						"start": 888.77,
						"text": "Do you think the Lama or the language model underlying that version two will be open sourced? Do you, do you're, do you have internal debate around that? The pros and cons and so on?"
					},
					{
						"avg_logprob": -0.10857371804423821,
						"end": 920.65,
						"speaker": "SPEAKER_01",
						"start": 901.29,
						"text": "This is, I mean, we were talking about the debates that we have internally and I think, um, I think the question is how to do it, right? I mean, it's, I think we, you know, we, we did the research license for V1 and, and I think the, the, the big thing that we're, that we're thinking about is, is basically like, what's the, what's the right, the right way."
					},
					{
						"avg_logprob": -0.10857371804423821,
						"end": 924.95,
						"speaker": "SPEAKER_00",
						"start": 920.85,
						"text": "So there was a leak that happened. I don't know if you can comment on it for V1."
					},
					{
						"avg_logprob": -0.10857371804423821,
						"end": 950.31,
						"speaker": "SPEAKER_01",
						"start": 925.41,
						"text": "You know, we released it as a research project, um, for research. Researchers to be able to use, but in doing so, we put it out there. So, um, you know, we were very clear that anyone who uses the code and the weights doesn't have a commercial license to put into products. And we've, we've generally seen people respect that, right? It's like, you don't have any reputable companies that are basically trying to put this into, into, um, their commercial products."
					},
					{
						"avg_logprob": -0.08752985991490116,
						"end": 960.07,
						"speaker": "SPEAKER_00",
						"start": 950.35,
						"text": "But, but yeah, but by sharing it with, you know, so many researchers, it's, it's, you know, it did leave the building. But, uh, what have you learned from that process that you might be able to."
					},
					{
						"avg_logprob": -0.13817631130787864,
						"end": 1022.02,
						"speaker": "SPEAKER_01",
						"start": 960.07,
						"text": "To apply to V2 about how to release it safely, effectively, uh, if, if you release it. Yeah. Well, I mean, I think a lot of the feedback, like I said, is just around, you know, different things around, you know, how do you fine tune models to make them more aligned and safer? And you see all the different data recipes that, um, you know, you mentioned a lot of different projects that are based on this. I mean, there's one at Berkeley, there's, you know, it was just like all over and, um, And people have tried a lot of different things and we've tried a bunch of stuff internally. So kind of where we're, we're making progress here, but also we're able to learn from some of the best ideas in the community. And, you know, I think it, you know, we want to just continue, continue pushing that forward, but I don't have any news to announce on, on, on, on, if that's, if that's what you're, you're asking. I mean, this is a thing that we're, uh, we're still, we're still kind of, you know, actively working through the. Yeah. The, the right way to move forward here."
					},
					{
						"avg_logprob": -0.15830291535732519,
						"end": 1063.02,
						"speaker": "SPEAKER_00",
						"start": 1022.14,
						"text": "The details of the secret sauce are still being developed. I see. Uh, can you comment on, what do you think of, uh, the thing that worked for GPT, which is the reinforcement learning with human feedback? So doing this alignment process, do you find it interesting? And as part of that, let me ask, cause I talked to Yann LeCun before talking to you today, he asked me to ask or suggested that I ask, do you think. LLM fine tuning will need to be crowdsourced. Wikipedia style, so crowdsourcing, so this kind of idea of how to integrate the human in the fine tuning of these foundation models. Yeah."
					},
					{
						"avg_logprob": -0.20231958271301898,
						"end": 1170.19,
						"speaker": "SPEAKER_01",
						"start": 1063.12,
						"text": "I think that's a really interesting idea that I've talked to Yon about a bunch. Um, and you were talking about how do you basically train these models to be as, as safe and aligned and responsible as possible. And, you know, different groups out there. Who are doing development, test different data recipes in fine tuning, but this idea that you, that you just mentioned is that at the end of the day, instead of having kind of one group fine tune some stuff and another group, you know, produce a different fine tuning recipe, and then us trying to figure out which one we think works best to produce the most aligned model. Um, I, I do think that it would be nice if you could get to a point where. You had a Wikipedia style collaborative way for a kind of a broader community to, um, to, to fine tune it as well. Now there's a lot of challenges in that, both from an infrastructure and like a community management and product perspective about how you do that. So I, I haven't worked that out yet, but, but I, as an idea, I think it's, it's quite compelling and I think it, it goes well with the ethos of open sourcing. The technology is also finding a way. To have a, a kind of community driven, um, a community driven training of it. Um, but I think that there are a lot of questions on this in general, these, this, these questions around what's the, the best way to produce aligned AI models. It's very much a research area and it's one that I think we will need to make as much progress on as the kind of core intelligence capability of the, of the, um, the models themselves."
					},
					{
						"avg_logprob": -0.12172379248565243,
						"end": 1201.67,
						"speaker": "SPEAKER_00",
						"start": 1170.67,
						"text": "Well, I just did a conversation with Jimmy Wales. The finalist. He's the founder of Wikipedia and to me, Wikipedia is one of the greatest websites ever created and is a kind of a miracle that it works. And I think it has to do with something that you mentioned, which is community. You have a small community of editors that somehow work together well, and they, uh, they handle very controversial topics and they handle it with balance and with grace, despite sort of the attacks that will often happen."
					},
					{
						"avg_logprob": -0.17628205535758254,
						"end": 1217.87,
						"speaker": "SPEAKER_01",
						"start": 1201.75,
						"text": "A lot of the time. I mean, it's not, it's. It has issues just like any other human system, but yes, I mean, the balance is, I mean, it's, uh, it's amazing what they've been able to achieve, but it's, it's also not perfect. And I think that that's, um, there's still a lot of challenges, right?"
					},
					{
						"avg_logprob": -0.10561784715142869,
						"end": 1286.83,
						"speaker": "SPEAKER_00",
						"start": 1217.99,
						"text": "It's, uh, the more controversial the topic, the more, the more difficult, uh, the, um, the journey towards quote unquote truth or knowledge or wisdom that Wikipedia tries to capture in the same way AI models. We need to be able to generate. Those same things, truth, knowledge, and wisdom, and how do you align those models that they generate, um, something that, uh, is closest to truth. There's these concerns about misinformation, all this kind of stuff that nobody can define. And that's a, it's a something that we together as a human species have to define, like what is truth and how to help AI systems generate that. Because one of the things that language models do really well. Is generating. Convincing sounding things that can be completely wrong. And so how do you align it, um, to be less wrong? And part of that is the training and part of that is the alignment and however you do the alignment stage. And just like you said, it's a very new and a very open research problem. Yeah."
					},
					{
						"avg_logprob": -0.2802556877786463,
						"end": 1378.51,
						"speaker": "SPEAKER_01",
						"start": 1286.83,
						"text": "And I think that there's also a lot of questions about whether the current architecture for LLMs. Yeah. Um, as you continue scaling it, what happens, um, I mean, a lot of the, a lot of what's been exciting in the last year is that there was, there was clearly a qualitative breakthrough where, you know, with, with some of the GPT models, um, that open AI put out and, and that others have been able to do as well. I think it reached a kind of level of quality where people like, wow, this is, this feels different. And, um, and like, it's going to be able to be the foundation for building a lot of awesome products. And experiences and value. But I think that the other realization that people have is, wow, we just made a breakthrough. Um, if there are other breakthroughs quickly, then I think that there's the sense that maybe where we're closer to general intelligence. But I think that that idea is predicated on the idea that, uh, I think people believe that there's still generally a bunch of additional breakthroughs to make and that it's, um, we just don't know how long it's going to take to get there. And, you know, one view that some people have. Yeah. Yeah. this doesn't tend to be my view as much, is that simply scaling the current LLMs and getting to higher parameter count models by itself will get to something that is closer to general intelligence. But I don't know. I tend to think that there's probably more fundamental steps that need to be"
					},
					{
						"avg_logprob": -0.11521291028667283,
						"end": 1409.39,
						"speaker": "SPEAKER_00",
						"start": 1378.51,
						"text": "taken along the way there. But still, the leaps taken with this extra alignment step is quite incredible, quite surprising to a lot of folks. And on top of that, when you start to have hundreds of millions of people potentially using a product that integrates that, you can start to see civilization transforming effects before you achieve super, quote unquote, super intelligence. It could be super transformative without being a super intelligence."
					},
					{
						"avg_logprob": -0.15959821680149475,
						"end": 1443.26,
						"speaker": "SPEAKER_01",
						"start": 1409.85,
						"text": "Oh, yeah. I mean, I think that there are going to be a lot of amazing products and value that can be made out of this. And I think that's going to be a lot of amazing things that are going to be created with the current level of technology. To some degree, I'm excited to work on a lot of those products over the next few years. And I think it would just create a tremendous amount of whiplash if the number of breakthroughs keeps like if they're keep on being stacked breakthroughs because I think to some degree, industry in the world needs some time to kind of build these breakthroughs into the products and experiences that we all use that we can actually benefit from them."
					},
					{
						"avg_logprob": -0.12455986156849794,
						"end": 1486.85,
						"speaker": "SPEAKER_01",
						"start": 1447.05,
						"text": "I don't know, I think that there's just a, like an awesome amount of stuff to do. I mean, I think about like all of the small businesses or individual entrepreneurs out there who now we're going to be able to get help coding the things that they need to go build things or designing the things that they need, or we'll be able to, you know, use these models to be able to do customer support for the people that they're, that they're serving, you know, over WhatsApp without having to, you know, it's, I think it's going to be a lot of amazing things. I think that that's, that's just going to be, I just think that this is all going to be, you know, super exciting. It's going to create better, better experiences for people and just unlock a ton of innovation and value."
					}
				]
			},
			"data_removed": false,
			"error": null,
			"status": "succeeded",
			"created_at": "2024-11-16T17:23:40.859Z",
			"webhook": "https://assistant.nicholasgriffin.workers.dev/webhooks/replicate?chatId=0.7sgbmp47y97&token=ll0k0XFKItAVcqWCMYFrc4ec6WZqIUfMPJk2Ac5PElGg4YVKXQPTR9jejed6tw13",
			"webhook_events_filter": ["output", "completed"],
			"urls": {
				"cancel": "https://api.replicate.com/v1/predictions/0rnvr7krqdrgp0ck6r09dk4f90/cancel",
				"get": "https://api.replicate.com/v1/predictions/0rnvr7krqdrgp0ck6r09dk4f90"
			},
			"completed_at": "2024-11-16T17:25:55.049015431Z",
			"metrics": {
				"predict_time": 134.088879541
			},
			"started_at": "2024-11-16T17:23:40.9601359Z"
		},
		"id": "rekkcq",
		"timestamp": 1731777822758
	},
	{
		"role": "assistant",
		"name": "podcast_summarise",
		"content": " Meta has developed LLama, which is a 65 billion parameter model. Meta has taken the approach of being quite open and academic in our development of AI. There's a lot of innovation out there that people can create.",
		"data": {
			"summary": " Meta has developed LLama, which is a 65 billion parameter model. Meta has taken the approach of being quite open and academic in our development of AI. There's a lot of innovation out there that people can create."
		},
		"id": "fovviq",
		"timestamp": 1731778003854
	},
	{
		"role": "assistant",
		"name": "podcast_generate_image",
		"content": "Podcast Featured Image Uploaded: [0.95w7cvqxyjv](https://assistant-assets.nickgriffin.uk/podcasts/0.95w7cvqxyjv/featured.png)",
		"data": {},
		"id": "4wjnc",
		"timestamp": 1731778011517
	},
	{
		"role": "assistant",
		"name": "podcast_summarise",
		"content": " Meta has developed LLama, which is a 65 billion parameter model. Meta has taken the approach of being quite open and academic in our development of AI. There's stuff that makes it more efficient to run on smaller computers.",
		"data": {
			"summary": " Meta has developed LLama, which is a 65 billion parameter model. Meta has taken the approach of being quite open and academic in our development of AI. There's stuff that makes it more efficient to run on smaller computers."
		},
		"id": "9le7br",
		"timestamp": 1731780785582
	}
]
