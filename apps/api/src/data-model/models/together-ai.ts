import type { ModelConfig } from "~/types";

export const togetherAiModelConfig: ModelConfig = {
	"meta-llama/Llama-3.3-70B-Instruct-Turbo": {
		name: "Llama 3.3 70B",
		description:
			"The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
		matchingModel: "meta-llama/Llama-3.3-70B-Instruct-Turbo",
		provider: "together-ai",
		contextWindow: 131072,
		maxTokens: 131072,
		costPer1kOutputTokens: 0.00088,
		costPer1kInputTokens: 0.00088,
		strengths: [
			"chat",
			"general_knowledge",
			"analysis",
			"creative",
			"multilingual",
		],
		contextComplexity: 4,
		reliability: 4,
		speed: 4,
		includedInRouter: true,
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		knowledgeCutoffDate: "December 2023",
		releaseDate: "December 6, 2024",
		lastUpdated: "December 6, 2024",
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		reasoningConfig: {
			enabled: false,
		},
	},
	"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": {
		name: "Meta Llama 3.3 70B Instruct Turbo Free",
		description:
			"The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
		matchingModel: "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
		provider: "together-ai",
		contextWindow: 8192,
		maxTokens: 4096,
		isFree: true,
		strengths: ["chat", "general_knowledge", "analysis", "multilingual"],
		contextComplexity: 4,
		reliability: 3,
		speed: 3,
		includedInRouter: true,
		modalities: {
			input: ["text"],
			output: ["text"],
		},
	},
	"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
		name: "Meta Llama 3.2 90B Vision Instruct Turbo",
		description:
			"Llama 3.2 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
		matchingModel: "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
		provider: "together-ai",
		multimodal: true,
		contextWindow: 128000,
		maxTokens: 4096,
		costPer1kOutputTokens: 0.0012,
		costPer1kInputTokens: 0.0012,
		strengths: ["vision", "analysis", "chat", "general_knowledge"],
		contextComplexity: 4,
		reliability: 4,
		speed: 4,
		includedInRouter: true,
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
	},
	"meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
		name: "Meta Llama 3.2 11B Vision Instruct Turbo",
		description:
			"Llama 3.2 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
		matchingModel: "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
		provider: "together-ai",
		multimodal: true,
		contextWindow: 32768,
		maxTokens: 4096,
		costPer1kOutputTokens: 0.00018,
		costPer1kInputTokens: 0.00018,
		strengths: ["vision", "chat", "general_knowledge"],
		contextComplexity: 3,
		reliability: 3,
		speed: 4,
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
	},
	"meta-llama/Llama-Vision-Free": {
		name: "Meta Llama Vision Free",
		description:
			"Llama 3.2 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
		matchingModel: "meta-llama/Llama-Vision-Free",
		provider: "together-ai",
		isFree: true,
		multimodal: true,
		contextWindow: 32768,
		maxTokens: 4096,
		strengths: ["vision", "chat"],
		contextComplexity: 3,
		reliability: 3,
		speed: 3,
		includedInRouter: true,
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
	},
	"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
		name: "Meta Llama 3.1 405B Instruct Turbo",
		description:
			"Llama 3.1 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
		matchingModel: "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
		provider: "together-ai",
		contextWindow: 128000,
		maxTokens: 4096,
		costPer1kOutputTokens: 0.0035,
		costPer1kInputTokens: 0.0035,
		strengths: [
			"chat",
			"general_knowledge",
			"analysis",
			"creative",
			"multilingual",
		],
		contextComplexity: 5,
		reliability: 5,
		speed: 4,
		isFeatured: true,
		includedInRouter: true,
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
	},
	"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free": {
		name: "DeepSeek R1 Distill Llama 70B Free",
		description:
			"DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.",
		matchingModel: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
		provider: "together-ai",
		isFree: true,
		contextWindow: 128000,
		maxTokens: 16384,
		strengths: ["reasoning", "analysis", "creative"],
		contextComplexity: 4,
		reliability: 3,
		speed: 3,
		includedInRouter: true,
		modalities: {
			input: ["text"],
			output: ["text"],
		},
	},
	"llama-4-maverick-instruct": {
		name: "Llama 4 Maverick Instruct",
		description:
			"Llama 4 Maverick is a large language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety.",
		matchingModel: "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
		provider: "together-ai",
		strengths: [
			"chat",
			"general_knowledge",
			"analysis",
			"creative",
			"multilingual",
			"coding",
		],
		contextComplexity: 4,
		reliability: 4,
		speed: 4,
		contextWindow: 1000000,
		maxTokens: 16384,
		isFeatured: true,
		includedInRouter: true,
		multimodal: true,
		modalities: {
			input: ["text"],
			output: ["text"],
		},
	},
	"Refuel-Llm-V2": {
		name: "Refuel LLM V2",
		matchingModel: "togethercomputer/Refuel-Llm-V2",
		description:
			"47B model optimized for data tasks such as classification, structured data extraction, and more.",
		contextWindow: 16000,
		provider: "together-ai",
		contextComplexity: 4,
		reliability: 4,
		speed: 4,
		modalities: {
			input: ["text"],
			output: ["text"],
		},
	},
	"Refuel-Llm-V2-Small": {
		name: "Refuel LLM V2 Small",
		matchingModel: "togethercomputer/Refuel-Llm-V2-Small",
		description:
			"8B model optimized for data tasks such as classification, structured data extraction, and more.",
		contextWindow: 8000,
		provider: "together-ai",
		contextComplexity: 3,
		reliability: 3,
		speed: 4,
		modalities: {
			input: ["text"],
			output: ["text"],
		},
	},
	"deepseek-ai/DeepSeek-R1": {
		name: "DeepSeek R1",
		matchingModel: "deepseek-ai/DeepSeek-R1",
		provider: "together-ai",
		knowledgeCutoffDate: "July 2024",
		releaseDate: "December 26, 2024",
		lastUpdated: "March 24, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: false,
		contextWindow: 163839,
		maxTokens: 163839,
		costPer1kInputTokens: 0.003,
		costPer1kOutputTokens: 0.007,
		reasoningConfig: {
			enabled: true,
		},
	},

	"deepseek-ai/DeepSeek-V3": {
		name: "DeepSeek V3",
		matchingModel: "deepseek-ai/DeepSeek-V3",
		provider: "together-ai",
		knowledgeCutoffDate: "July 2024",
		releaseDate: "January 20, 2025",
		lastUpdated: "May 29, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 131072,
		maxTokens: 131072,
		costPer1kInputTokens: 0.00125,
		costPer1kOutputTokens: 0.00125,
		reasoningConfig: {
			enabled: true,
		},
	},

	"deepseek-ai/DeepSeek-V3-1": {
		name: "DeepSeek V3.1",
		matchingModel: "deepseek-ai/DeepSeek-V3-1",
		provider: "together-ai",
		knowledgeCutoffDate: "August 2025",
		releaseDate: "August 21, 2025",
		lastUpdated: "August 21, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 131072,
		maxTokens: 131072,
		costPer1kInputTokens: 0.0006,
		costPer1kOutputTokens: 0.0017,
		reasoningConfig: {
			enabled: true,
		},
	},

	"essentialai/Rnj-1-Instruct": {
		name: "Rnj-1 Instruct",
		matchingModel: "essentialai/Rnj-1-Instruct",
		provider: "together-ai",
		knowledgeCutoffDate: "October 2024",
		releaseDate: "December 5, 2025",
		lastUpdated: "December 5, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 32768,
		maxTokens: 32768,
		costPer1kInputTokens: 0.00015,
		costPer1kOutputTokens: 0.00015,
		reasoningConfig: {
			enabled: false,
		},
	},

	"moonshotai/Kimi-K2-Instruct": {
		name: "Kimi K2 Instruct",
		matchingModel: "moonshotai/Kimi-K2-Instruct",
		provider: "together-ai",
		knowledgeCutoffDate: "October 2024",
		releaseDate: "July 14, 2025",
		lastUpdated: "July 14, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 131072,
		maxTokens: 131072,
		costPer1kInputTokens: 0.001,
		costPer1kOutputTokens: 0.003,
		reasoningConfig: {
			enabled: false,
		},
	},

	"moonshotai/Kimi-K2-Instruct-0905": {
		name: "Kimi K2 Instruct-0905",
		matchingModel: "moonshotai/Kimi-K2-Instruct-0905",
		provider: "together-ai",
		knowledgeCutoffDate: "September 2025",
		releaseDate: "September 5, 2025",
		lastUpdated: "September 5, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 262144,
		maxTokens: 262144,
		costPer1kInputTokens: 0.001,
		costPer1kOutputTokens: 0.003,
		reasoningConfig: {
			enabled: false,
		},
	},

	"moonshotai/Kimi-K2-Thinking": {
		name: "Kimi K2 Thinking",
		matchingModel: "moonshotai/Kimi-K2-Thinking",
		provider: "together-ai",
		knowledgeCutoffDate: "July 2025",
		releaseDate: "November 6, 2025",
		lastUpdated: "November 6, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 262144,
		maxTokens: 262144,
		costPer1kInputTokens: 0.0012,
		costPer1kOutputTokens: 0.004,
		reasoningConfig: {
			enabled: true,
		},
	},

	"moonshotai/Kimi-K2.5": {
		name: "Kimi K2.5",
		matchingModel: "moonshotai/Kimi-K2.5",
		provider: "together-ai",
		knowledgeCutoffDate: "January 2026",
		releaseDate: "January 27, 2026",
		lastUpdated: "January 27, 2026",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 262144,
		maxTokens: 262144,
		costPer1kInputTokens: 0.0005,
		costPer1kOutputTokens: 0.0028,
		reasoningConfig: {
			enabled: true,
		},
	},

	"openai/gpt-oss-120b": {
		name: "GPT OSS 120B",
		matchingModel: "openai/gpt-oss-120b",
		provider: "together-ai",
		knowledgeCutoffDate: "August 2025",
		releaseDate: "August 5, 2025",
		lastUpdated: "August 5, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 131072,
		maxTokens: 131072,
		costPer1kInputTokens: 0.00015,
		costPer1kOutputTokens: 0.0006,
		reasoningConfig: {
			enabled: true,
		},
	},

	"Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
		name: "Qwen3 235B A22B Instruct 2507 FP8",
		matchingModel: "Qwen/Qwen3-235B-A22B-Instruct-2507-tput",
		provider: "together-ai",
		knowledgeCutoffDate: "July 2025",
		releaseDate: "July 25, 2025",
		lastUpdated: "July 25, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 262144,
		maxTokens: 262144,
		costPer1kInputTokens: 0.0002,
		costPer1kOutputTokens: 0.0006,
		reasoningConfig: {
			enabled: true,
		},
	},

	"Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
		name: "Qwen3 Coder 480B A35B Instruct",
		matchingModel: "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
		provider: "together-ai",
		knowledgeCutoffDate: "April 2025",
		releaseDate: "July 23, 2025",
		lastUpdated: "July 23, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 262144,
		maxTokens: 262144,
		costPer1kInputTokens: 0.002,
		costPer1kOutputTokens: 0.002,
		reasoningConfig: {
			enabled: false,
		},
	},

	"Qwen/Qwen3-Coder-Next-FP8": {
		name: "Qwen3 Coder Next FP8",
		matchingModel: "Qwen/Qwen3-Coder-Next-FP8",
		provider: "together-ai",
		knowledgeCutoffDate: "February 3, 2026",
		releaseDate: "February 3, 2026",
		lastUpdated: "February 3, 2026",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 262144,
		maxTokens: 262144,
		costPer1kInputTokens: 0.0005,
		costPer1kOutputTokens: 0.0012,
		reasoningConfig: {
			enabled: true,
		},
	},

	"Qwen/Qwen3-Next-80B-A3B-Instruct": {
		name: "Qwen3-Next-80B-A3B-Instruct",
		matchingModel: "Qwen/Qwen3-Next-80B-A3B-Instruct",
		provider: "together-ai",
		knowledgeCutoffDate: "July 2025",
		releaseDate: "July 25, 2025",
		lastUpdated: "July 25, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 262144,
		maxTokens: 262144,
		costPer1kInputTokens: 0.00015,
		costPer1kOutputTokens: 0.0015,
		reasoningConfig: {
			enabled: false,
		},
	},

	"zai-org/GLM-4.6": {
		name: "GLM 4.6",
		matchingModel: "zai-org/GLM-4.6",
		provider: "together-ai",
		knowledgeCutoffDate: "September 2025",
		releaseDate: "September 30, 2025",
		lastUpdated: "September 30, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 200000,
		maxTokens: 200000,
		costPer1kInputTokens: 0.0006,
		costPer1kOutputTokens: 0.0022,
		reasoningConfig: {
			enabled: false,
		},
	},

	"zai-org/GLM-4.7": {
		name: "GLM-4.7",
		matchingModel: "zai-org/GLM-4.7",
		provider: "together-ai",
		knowledgeCutoffDate: "July 2025",
		releaseDate: "July 25, 2025",
		lastUpdated: "July 25, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsToolCalls: true,
		contextWindow: 200000,
		maxTokens: 200000,
		costPer1kInputTokens: 0.00045,
		costPer1kOutputTokens: 0.002,
		reasoningConfig: {
			enabled: true,
		},
	},
};
