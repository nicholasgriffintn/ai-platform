import type { ModelConfig } from "~/types";
import {
	createModelConfig,
	createModelConfigObject,
} from "~/lib/providers/models/utils";

const PROVIDER = "mistral";

export const mistralModelConfig: ModelConfig = createModelConfigObject([
	createModelConfig("mistral-small-creative", PROVIDER, {
		name: "Mistral Small Creative (Labs)",
		matchingModel: "labs-mistral-small-creative",
		description:
			"An experimental specialized small model trained on meticulously curated data, designed for creative writing, narrative generation, roleplay and character-driven dialog, general-purpose instruction following and conversational agents.",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		contextWindow: 32768,
	}),

	createModelConfig("mistral-ocr-latest", PROVIDER, {
		name: "Mistral OCR",
		matchingModel: "mistral-ocr-latest",
		description:
			"A document OCR (Optical Character Recognition) processor that works with PDFs and images.",
		modalities: {
			input: ["document", "image"],
			output: ["text"],
		},
	}),
	createModelConfig("magistral-small", PROVIDER, {
		name: "Magistral Small",
		matchingModel: "magistral-small-latest",
		description:
			"The first reasoning model by Mistral AI â€” excelling in domain-specific, transparent, and multilingual reasoning.",
		knowledgeCutoffDate: "June 2025",
		releaseDate: "March 17, 2025",
		lastUpdated: "March 17, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: true },
		supportsToolCalls: true,
		contextWindow: 128000,
		maxTokens: 128000,
		costPer1kInputTokens: 0.0005,
		costPer1kOutputTokens: 0.0015,
		strengths: [
			"reasoning",
			"analysis",
			"multilingual",
			"chat",
			"general_knowledge",
		],
		contextComplexity: 4,
		reliability: 4,
		speed: 3,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
		requiresThinkingPrompt: true,
	}),

	createModelConfig("devstral-small", PROVIDER, {
		name: "Devstral Small",
		matchingModel: "devstral-small-latest",
		description:
			"Devstral Small is an agentic LLM for software engineering tasks.",
		knowledgeCutoffDate: "May 2025",
		releaseDate: "July 10, 2025",
		lastUpdated: "July 10, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 128000,
		maxTokens: 128000,
		costPer1kInputTokens: 0.0001,
		costPer1kOutputTokens: 0.0003,
		strengths: ["coding", "analysis", "agents"],
		contextComplexity: 3,
		reliability: 4,
		speed: 4,
		includedInRouter: true,
		supportsFim: true,
		supportsArtifacts: true,
	}),

	createModelConfig("open-mixtral-8x22b", PROVIDER, {
		name: "Mixtral 8x22B",
		matchingModel: "open-mixtral-8x22b",
		description:
			"Mixtral 8x22B is a sparse mixture-of-experts model with strong performance across coding, mathematics, and multilingual tasks.",
		knowledgeCutoffDate: "April 2024",
		releaseDate: "April 17, 2024",
		lastUpdated: "April 17, 2024",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 64000,
		maxTokens: 64000,
		costPer1kInputTokens: 0.002,
		costPer1kOutputTokens: 0.006,
		strengths: ["reasoning", "analysis", "multilingual", "coding"],
		contextComplexity: 4,
		reliability: 4,
		speed: 3,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("mistral-large", PROVIDER, {
		name: "Mistral Large",
		matchingModel: "mistral-large-latest",
		description:
			"Capable in code generation, mathematics, and reasoning with support for dozens of languages.",
		knowledgeCutoffDate: "November 2024",
		releaseDate: "November 1, 2024",
		lastUpdated: "November 4, 2024",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		card: "https://www.prompthub.us/models/mistral-large",
		contextWindow: 131072,
		maxTokens: 16384,
		costPer1kInputTokens: 0.002,
		costPer1kOutputTokens: 0.006,
		strengths: [
			"chat",
			"general_knowledge",
			"analysis",
			"creative",
			"reasoning",
		],
		contextComplexity: 4,
		reliability: 4,
		speed: 3,
		isFeatured: true,
		includedInRouter: true,
		supportsFim: true,
		supportsArtifacts: true,
	}),

	createModelConfig("open-mistral-7b", PROVIDER, {
		name: "Mistral 7B",
		matchingModel: "open-mistral-7b",
		description:
			"The first dense model released by Mistral AI, perfect for customization.",
		knowledgeCutoffDate: "December 2023",
		releaseDate: "September 27, 2023",
		lastUpdated: "September 27, 2023",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 8000,
		maxTokens: 8000,
		costPer1kInputTokens: 0.00025,
		costPer1kOutputTokens: 0.00025,
		strengths: ["chat", "general_knowledge", "multilingual"],
		contextComplexity: 2,
		reliability: 3,
		speed: 5,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("pixtral-large", PROVIDER, {
		name: "Pixtral Large",
		matchingModel: "pixtral-large-latest",
		description:
			"Latest multimodal model with advanced vision capabilities for image understanding and analysis.",
		knowledgeCutoffDate: "November 2024",
		releaseDate: "November 1, 2024",
		lastUpdated: "November 4, 2024",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		card: "https://www.prompthub.us/models/pixtral",
		contextWindow: 128000,
		maxTokens: 128000,
		costPer1kInputTokens: 0.002,
		costPer1kOutputTokens: 0.006,
		strengths: ["vision", "analysis", "multilingual"],
		contextComplexity: 4,
		reliability: 4,
		speed: 3,
		multimodal: true,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("mistral-medium", PROVIDER, {
		name: "Mistral Medium",
		matchingModel: "mistral-medium-latest",
		description:
			"Capable in code generation, mathematics, and reasoning with support for dozens of languages.",
		knowledgeCutoffDate: "May 2025",
		releaseDate: "May 7, 2025",
		lastUpdated: "May 10, 2025",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		card: "https://www.prompthub.us/models/mistral-medium",
		contextWindow: 128000,
		maxTokens: 16384,
		costPer1kInputTokens: 0.0004,
		costPer1kOutputTokens: 0.002,
		strengths: ["chat", "general_knowledge", "analysis", "creative", "vision"],
		contextComplexity: 4,
		reliability: 4,
		speed: 3,
		multimodal: true,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("codestral", PROVIDER, {
		name: "Codestral",
		matchingModel: "codestral-latest",
		description:
			"Codestral is Mistral AI's first-ever code model designed for code generation tasks.",
		knowledgeCutoffDate: "October 2024",
		releaseDate: "May 29, 2024",
		lastUpdated: "January 4, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		card: "https://www.prompthub.us/models/codestral",
		contextWindow: 256000,
		maxTokens: 4096,
		costPer1kInputTokens: 0.0003,
		costPer1kOutputTokens: 0.0009,
		strengths: ["coding", "analysis", "multilingual"],
		contextComplexity: 4,
		reliability: 4,
		speed: 3,
		isFeatured: true,
		includedInRouter: true,
		supportsFim: true,
		supportsArtifacts: true,
	}),

	createModelConfig("devstral-medium", PROVIDER, {
		name: "Devstral Medium",
		matchingModel: "devstral-medium-2507",
		description:
			"Devstral Medium offers exceptional performance at a competitive price point for software engineering.",
		knowledgeCutoffDate: "May 2025",
		releaseDate: "July 10, 2025",
		lastUpdated: "July 10, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 128000,
		maxTokens: 128000,
		costPer1kInputTokens: 0.0004,
		costPer1kOutputTokens: 0.002,
		strengths: ["coding", "analysis", "agents"],
		contextComplexity: 4,
		reliability: 4,
		speed: 3,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
		supportsFim: true,
	}),

	createModelConfig("open-mixtral-8x7b", PROVIDER, {
		name: "Mixtral 8x7B",
		matchingModel: "open-mixtral-8x7b",
		description:
			"Sparse mixture-of-experts model outperforming Llama 2 70B on most benchmarks.",
		knowledgeCutoffDate: "January 2024",
		releaseDate: "December 11, 2023",
		lastUpdated: "December 11, 2023",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 32000,
		maxTokens: 32000,
		costPer1kInputTokens: 0.0007,
		costPer1kOutputTokens: 0.0007,
		strengths: ["reasoning", "analysis", "multilingual", "coding"],
		contextComplexity: 4,
		reliability: 4,
		speed: 3,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("pixtral-12b", PROVIDER, {
		name: "Pixtral 12B",
		matchingModel: "pixtral-12b",
		description:
			"Multimodal model with vision capabilities for image understanding and analysis.",
		knowledgeCutoffDate: "September 2024",
		releaseDate: "September 1, 2024",
		lastUpdated: "September 1, 2024",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 128000,
		maxTokens: 128000,
		costPer1kInputTokens: 0.00015,
		costPer1kOutputTokens: 0.00015,
		strengths: ["vision", "analysis", "multilingual"],
		contextComplexity: 3,
		reliability: 4,
		speed: 4,
		multimodal: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("mistral-small", PROVIDER, {
		name: "Mistral Small",
		matchingModel: "mistral-small-latest",
		description:
			"Mistral Small is a lightweight model designed for cost-effective use in tasks like translation and summarization.",
		knowledgeCutoffDate: "March 2025",
		releaseDate: "September 1, 2024",
		lastUpdated: "September 4, 2024",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		card: "https://www.prompthub.us/models/mistral-small",
		contextWindow: 128000,
		maxTokens: 16384,
		costPer1kInputTokens: 0.0001,
		costPer1kOutputTokens: 0.0003,
		strengths: [
			"chat",
			"general_knowledge",
			"analysis",
			"creative",
			"multilingual",
			"vision",
		],
		contextComplexity: 3,
		reliability: 3,
		speed: 4,
		multimodal: true,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("ministral-14b", PROVIDER, {
		name: "Ministral 14B",
		matchingModel: "ministral-14b-latest",
		description:
			"Ministral 3 14B is the largest model in the Ministral 3 family, offering state-of-the-art capabilities and performance comparable to its larger Mistral Small 3.2 24B counterpart. Optimized for local deployment, it delivers high performance across diverse hardware, including local setups.",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 256000,
		maxTokens: 256000,
		costPer1kInputTokens: 0.0002,
		costPer1kOutputTokens: 0.0002,
		strengths: [
			"chat",
			"general_knowledge",
			"analysis",
			"creative",
			"multilingual",
			"vision",
		],
		contextComplexity: 2,
		reliability: 3,
		speed: 3,
		multimodal: true,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("ministral-8b", PROVIDER, {
		name: "Ministral 8b",
		matchingModel: "ministral-8b-latest",
		description:
			"Ministral 3 8B is a powerful and efficient model in the Ministral 3 family, offering best-in-class text and vision capabilities. Built for edge deployment, it delivers high performance across diverse hardware, including local setups.",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 256000,
		maxTokens: 256000,
		costPer1kInputTokens: 0.00015,
		costPer1kOutputTokens: 0.00015,
		strengths: [
			"chat",
			"general_knowledge",
			"analysis",
			"creative",
			"multilingual",
			"vision",
		],
		contextComplexity: 2,
		reliability: 3,
		speed: 3,
		multimodal: true,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("ministral-3-3b", PROVIDER, {
		name: "Ministral 3B",
		matchingModel: "ministral-3b-latest",
		description:
			"Ministral 3 3B is the smallest and most efficient model in the Ministral 3 family, offering robust language and vision capabilities in a compact package. Designed for edge deployment, it delivers high performance across diverse hardware, including local setups.",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 256000,
		maxTokens: 256000,
		costPer1kInputTokens: 0.0001,
		costPer1kOutputTokens: 0.0001,
		strengths: [
			"chat",
			"general_knowledge",
			"analysis",
			"creative",
			"multilingual",
			"vision",
		],
		contextComplexity: 1,
		reliability: 3,
		speed: 5,
		multimodal: true,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("devstral-small-latest", PROVIDER, {
		name: "Devstral Small 2505",
		matchingModel: "devstral-small-latest",
		description:
			"Earlier version of Devstral Small for software engineering tasks.",
		knowledgeCutoffDate: "May 2025",
		releaseDate: "May 7, 2025",
		lastUpdated: "May 7, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		contextWindow: 128000,
		maxTokens: 128000,
		costPer1kInputTokens: 0.0001,
		costPer1kOutputTokens: 0.0003,
		strengths: ["coding", "analysis"],
		contextComplexity: 3,
		reliability: 3,
		speed: 4,
		includedInRouter: false,
		supportsArtifacts: true,
		supportsFim: true,
	}),

	createModelConfig("magistral-medium", PROVIDER, {
		name: "Magistral Medium",
		matchingModel: "magistral-medium-latest",
		description:
			"Enhanced reasoning model by Mistral AI with improved capabilities for complex problem-solving.",
		knowledgeCutoffDate: "June 2025",
		releaseDate: "March 17, 2025",
		lastUpdated: "March 20, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: true },
		supportsToolCalls: true,
		contextWindow: 128000,
		maxTokens: 16384,
		costPer1kInputTokens: 0.002,
		costPer1kOutputTokens: 0.005,
		strengths: [
			"reasoning",
			"analysis",
			"multilingual",
			"chat",
			"general_knowledge",
		],
		contextComplexity: 4,
		reliability: 4,
		speed: 3,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
		requiresThinkingPrompt: true,
	}),

	createModelConfig("mistral-tiny", PROVIDER, {
		name: "Mistral Tiny",
		matchingModel: "mistral-tiny-latest",
		description:
			"A projected ultra-lightweight open-weight model in the Mistral AI family, targeting the lower bound of LLM size/performance tradeoffs.",
		knowledgeCutoffDate: "July 2024",
		releaseDate: "July 1, 2024",
		lastUpdated: "July 1, 2024",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		reasoningConfig: { enabled: false },
		supportsToolCalls: true,
		card: "https://www.prompthub.us/models/mistral-nemo",
		contextWindow: 128000,
		maxTokens: 128000,
		costPer1kInputTokens: 0.00015,
		costPer1kOutputTokens: 0.00015,
		strengths: [
			"chat",
			"general_knowledge",
			"analysis",
			"creative",
			"multilingual",
		],
		contextComplexity: 3,
		reliability: 3,
		speed: 4,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("voxtral-small", PROVIDER, {
		name: "Voxtral Small",
		matchingModel: "voxtral-small-latest",
		description:
			"Audio input capabilities enable models to chat and understand audio directly, this can be used for both chat use cases via audio or for optimal transcription purposes.",
		modalities: {
			input: ["text"],
			output: ["speech"],
		},
		supportsAudio: true,
	}),

	createModelConfig("voxtral-mini", PROVIDER, {
		name: "Voxtral Mini",
		matchingModel: "voxtral-mini-latest",
		description:
			"Audio input capabilities enable models to chat and understand audio directly, this can be used for both chat use cases via audio or for optimal transcription purposes.",
		modalities: {
			input: ["text"],
			output: ["speech"],
		},
		supportsAudio: true,
	}),

	createModelConfig("mistral-embed", PROVIDER, {
		name: "Mistral Embed",
		matchingModel: "mistral-embed",
		description: "An embedding model for text content",
		modalities: {
			input: ["embedding"],
			output: ["embedding"],
		},
	}),

	createModelConfig("codestral-embed", PROVIDER, {
		name: "Codestral Embed",
		matchingModel: "codestral-embed",
		description: "An embedding model for code content",
		modalities: {
			input: ["embedding"],
			output: ["embedding"],
		},
	}),

	createModelConfig("mistral-moderation-latest", PROVIDER, {
		name: "Mistral Moderation",
		matchingModel: "mistral-moderation-latest",
		description: "A moderation model for content filtering",
		modalities: {
			input: ["moderation"],
			output: ["moderation"],
		},
	}),
]);
