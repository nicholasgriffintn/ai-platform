import type { ModelConfig } from "~/types";
import {
	createModelConfig,
	createModelConfigObject,
} from "~/lib/providers/models/utils";

const PROVIDER = "inference";

export const inferenceModelConfig: ModelConfig = createModelConfigObject([
	createModelConfig("mistral/mistral-nemo-12b-instruct", PROVIDER, {
		name: "Mistral Nemo 12B Instruct",
		matchingModel: "mistral/mistral-nemo-12b-instruct",
		description:
			"Trained jointly by Mistral AI and NVIDIA, it significantly outperforms existing models smaller or similar in size.",
		knowledgeCutoffDate: "December 2024",
		releaseDate: "January 1, 2025",
		lastUpdated: "January 1, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsReasoning: false,
		supportsToolCalls: true,
		contextWindow: 16000,
		maxTokens: 4096,
		costPer1kInputTokens: 0.000038,
		costPer1kOutputTokens: 0.0001,
		strengths: ["chat", "general_knowledge", "analysis", "multilingual"],
		contextComplexity: 3,
		reliability: 3,
		speed: 4,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("osmosis/osmosis-structure-0.6b", PROVIDER, {
		name: "Osmosis Structure 0.6B",
		matchingModel: "osmosis/osmosis-structure-0.6b",
		description:
			"Specialized small model optimized for structured data processing and analysis tasks.",
		knowledgeCutoffDate: "December 2024",
		releaseDate: "January 1, 2025",
		lastUpdated: "January 1, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsReasoning: false,
		supportsToolCalls: true,
		contextWindow: 4000,
		maxTokens: 2048,
		costPer1kInputTokens: 0.0001,
		costPer1kOutputTokens: 0.0005,
		strengths: ["analysis", "instruction"],
		contextComplexity: 2,
		reliability: 3,
		speed: 5,
		includedInRouter: false,
		supportsArtifacts: true,
	}),

	createModelConfig("google/gemma-3", PROVIDER, {
		name: "Google Gemma 3",
		matchingModel: "google/gemma-3",
		description:
			"Google's latest Gemma model with multimodal capabilities and large context window.",
		knowledgeCutoffDate: "December 2024",
		releaseDate: "January 1, 2025",
		lastUpdated: "January 1, 2025",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		supportsReasoning: false,
		supportsToolCalls: true,
		contextWindow: 125000,
		maxTokens: 4096,
		costPer1kInputTokens: 0.00015,
		costPer1kOutputTokens: 0.0003,
		strengths: ["vision", "analysis", "general_knowledge", "multilingual"],
		contextComplexity: 4,
		reliability: 4,
		speed: 4,
		multimodal: true,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("meta/llama-3.2-1b-instruct", PROVIDER, {
		name: "Llama 3.2 1B Instruct",
		matchingModel: "meta/llama-3.2-1b-instruct",
		description:
			"Ultra-efficient 1B parameter Llama model optimized for fast inference and low-resource environments.",
		knowledgeCutoffDate: "December 2023",
		releaseDate: "January 1, 2025",
		lastUpdated: "January 1, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsReasoning: false,
		supportsToolCalls: true,
		contextWindow: 16000,
		maxTokens: 4096,
		costPer1kInputTokens: 0.00001,
		costPer1kOutputTokens: 0.00001,
		strengths: ["chat", "instruction"],
		contextComplexity: 2,
		reliability: 3,
		speed: 5,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("meta/llama-3.1-8b-instruct", PROVIDER, {
		name: "Llama 3.1 8B Instruct",
		matchingModel: "meta/llama-3.1-8b-instruct",
		description:
			"Medium-sized Llama model offering good balance between performance and efficiency.",
		knowledgeCutoffDate: "December 2023",
		releaseDate: "January 1, 2025",
		lastUpdated: "January 1, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsReasoning: false,
		supportsToolCalls: true,
		contextWindow: 16000,
		maxTokens: 4096,
		costPer1kInputTokens: 0.000025,
		costPer1kOutputTokens: 0.000025,
		strengths: ["chat", "general_knowledge", "coding", "analysis"],
		contextComplexity: 3,
		reliability: 3,
		speed: 4,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("meta/llama-3.2-3b-instruct", PROVIDER, {
		name: "Llama 3.2 3B Instruct",
		matchingModel: "meta/llama-3.2-3b-instruct",
		description:
			"Compact 3B parameter Llama model optimized for efficient inference with good capabilities.",
		knowledgeCutoffDate: "December 2023",
		releaseDate: "January 1, 2025",
		lastUpdated: "January 1, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: true,
		supportsReasoning: false,
		supportsToolCalls: true,
		contextWindow: 16000,
		maxTokens: 4096,
		costPer1kInputTokens: 0.00002,
		costPer1kOutputTokens: 0.00002,
		strengths: ["chat", "general_knowledge", "instruction"],
		contextComplexity: 3,
		reliability: 3,
		speed: 4,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("meta/llama-3.2-11b-vision-instruct", PROVIDER, {
		name: "Llama 3.2 11B Vision Instruct",
		matchingModel: "meta/llama-3.2-11b-vision-instruct",
		description:
			"Multimodal Llama model with vision capabilities for image understanding and analysis.",
		knowledgeCutoffDate: "December 2023",
		releaseDate: "January 1, 2025",
		lastUpdated: "January 1, 2025",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		supportsReasoning: false,
		supportsToolCalls: true,
		contextWindow: 16000,
		maxTokens: 4096,
		costPer1kInputTokens: 0.000055,
		costPer1kOutputTokens: 0.000055,
		strengths: ["vision", "analysis", "chat", "instruction"],
		contextComplexity: 3,
		reliability: 4,
		speed: 4,
		multimodal: true,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),

	createModelConfig("qwen/qwen3-embedding-4b", PROVIDER, {
		name: "Qwen 3 Embedding 4B",
		matchingModel: "qwen/qwen3-embedding-4b",
		description:
			"Specialized embedding model for generating high-quality text representations.",
		knowledgeCutoffDate: "December 2024",
		releaseDate: "January 1, 2025",
		lastUpdated: "January 1, 2025",
		modalities: {
			input: ["text"],
			output: ["text"],
		},
		supportsAttachments: false,
		supportsTemperature: false,
		supportsReasoning: false,
		supportsToolCalls: false,
		contextWindow: 32000,
		maxTokens: 2048,
		costPer1kInputTokens: 0.00001,
		costPer1kOutputTokens: 0,
		strengths: ["general_knowledge"],
		contextComplexity: 2,
		reliability: 4,
		speed: 5,
		includedInRouter: false,
		supportsArtifacts: false,
	}),

	createModelConfig("qwen/qwen-2.5-7b-vision-instruct", PROVIDER, {
		name: "Qwen 2.5 7B Vision Instruct",
		matchingModel: "qwen/qwen-2.5-7b-vision-instruct",
		description:
			"Qwen's multimodal model with vision capabilities and large context window support.",
		knowledgeCutoffDate: "December 2024",
		releaseDate: "January 1, 2025",
		lastUpdated: "January 1, 2025",
		modalities: {
			input: ["text", "image"],
			output: ["text"],
		},
		supportsAttachments: true,
		supportsTemperature: true,
		supportsReasoning: false,
		supportsToolCalls: true,
		contextWindow: 125000,
		maxTokens: 4096,
		costPer1kInputTokens: 0.0002,
		costPer1kOutputTokens: 0.0002,
		strengths: ["vision", "analysis", "multilingual", "general_knowledge"],
		contextComplexity: 4,
		reliability: 4,
		speed: 4,
		multimodal: true,
		isFeatured: true,
		includedInRouter: true,
		supportsArtifacts: true,
	}),
]);
