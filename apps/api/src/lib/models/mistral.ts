import type { ModelConfig } from "~/types";
import { createModelConfig, createModelConfigObject } from "./utils";

const PROVIDER = "mistral";

export const mistralModelConfig: ModelConfig = createModelConfigObject([
  createModelConfig("mistral-medium", PROVIDER, {
    name: "Mistral Medium",
    matchingModel: "mistral-medium-latest",
    description:
      "Capable in code generation, mathematics, and reasoning with support for dozens of languages.",
    type: ["text"],
    supportsFunctions: true,
    isFree: true,
    card: "https://www.prompthub.us/models/mistral-medium",
    contextWindow: 128000,
    maxTokens: 128000,
    costPer1kInputTokens: 0.002,
    costPer1kOutputTokens: 0.006,
    strengths: ["chat", "general_knowledge", "analysis", "creative"],
    contextComplexity: 4,
    reliability: 4,
    speed: 3,
    isFeatured: true,
    includedInRouter: true,
    supportsArtifacts: true,
  }),

  createModelConfig("mistral-large", PROVIDER, {
    name: "Mistral Large",
    matchingModel: "mistral-large-latest",
    description:
      "Capable in code generation, mathematics, and reasoning with support for dozens of languages.",
    type: ["text"],
    supportsFunctions: true,
    isFree: true,
    card: "https://www.prompthub.us/models/mistral-large",
    contextWindow: 128000,
    maxTokens: 128000,
    costPer1kInputTokens: 0.002,
    costPer1kOutputTokens: 0.006,
    strengths: ["chat", "general_knowledge", "analysis", "creative"],
    contextComplexity: 4,
    reliability: 4,
    speed: 3,
    isFeatured: true,
    includedInRouter: true,
    supportsArtifacts: true,
  }),

  createModelConfig("mistral-small", PROVIDER, {
    name: "Mistral Small",
    matchingModel: "mistral-small-latest",
    description:
      "Mistral Small is a lightweight model designed for cost-effective use in tasks like translation and summarization.",
    type: ["text"],
    supportsFunctions: true,
    isFree: true,
    card: "https://www.prompthub.us/models/mistral-small",
    contextWindow: 128000,
    maxTokens: 128000,
    costPer1kInputTokens: 0.002,
    costPer1kOutputTokens: 0.006,
    strengths: [
      "chat",
      "general_knowledge",
      "analysis",
      "creative",
      "multilingual",
    ],
    contextComplexity: 3,
    reliability: 3,
    speed: 4,
    isFeatured: true,
    includedInRouter: true,
    supportsArtifacts: true,
  }),

  createModelConfig("devstral-small", PROVIDER, {
    name: "Devstral Small",
    matchingModel: "devstral-small-latest",
    description:
      "Devstral Small is an agentic LLM for software engineering tasks.",
    type: ["coding"],
    supportsFunctions: true,
    isFree: true,
    contextWindow: 128000,
    maxTokens: 128000,
    costPer1kInputTokens: 0.002,
    costPer1kOutputTokens: 0.006,
    strengths: ["coding", "agents"],
    contextComplexity: 3,
    reliability: 3,
    speed: 4,
    isFeatured: true,
    includedInRouter: true,
    supportsArtifacts: true,
  }),

  createModelConfig("devstral-medium", PROVIDER, {
    name: "Devstral Medium",
    matchingModel: "devstral-medium-latest",
    description:
      "Devstral Medium offers exceptional performance at a competitive price point.",
    type: ["coding"],
    supportsFunctions: true,
    isFree: true,
    contextWindow: 128000,
    maxTokens: 128000,
    costPer1kInputTokens: 0.4,
    costPer1kOutputTokens: 2,
    strengths: ["coding", "agents"],
    contextComplexity: 4,
    reliability: 4,
    speed: 4,
    isFeatured: true,
    includedInRouter: true,
    supportsArtifacts: true,
  }),

  createModelConfig("magistral-small", PROVIDER, {
    name: "Magistral Small",
    matchingModel: "magistral-small-latest",
    description:
      "The first reasoning model by Mistral AI — excelling in domain-specific, transparent, and multilingual reasoning.",
    type: ["text"],
    supportsFunctions: true,
    isFree: true,
    contextWindow: 128000,
    maxTokens: 128000,
    costPer1kInputTokens: 0.0005,
    costPer1kOutputTokens: 0.0015,
    strengths: [
      "chat",
      "general_knowledge",
      "analysis",
      "creative",
      "multilingual",
      "reasoning",
    ],
    hasThinking: true,
    requiresThinkingPrompt: true,
    contextComplexity: 3,
    reliability: 3,
    speed: 3,
    isFeatured: true,
    includedInRouter: true,
    supportsArtifacts: true,
  }),

  createModelConfig("magistral-medium", PROVIDER, {
    name: "Magistral Medium",
    matchingModel: "magistral-medium-latest",
    description:
      "The first reasoning model by Mistral AI — excelling in domain-specific, transparent, and multilingual reasoning.",
    type: ["text"],
    supportsFunctions: true,
    isFree: true,
    contextWindow: 128000,
    maxTokens: 128000,
    costPer1kInputTokens: 0.002,
    costPer1kOutputTokens: 0.005,
    strengths: [
      "chat",
      "general_knowledge",
      "analysis",
      "creative",
      "multilingual",
      "reasoning",
    ],
    hasThinking: true,
    requiresThinkingPrompt: true,
    contextComplexity: 3,
    reliability: 3,
    speed: 3,
    isFeatured: true,
    includedInRouter: true,
    supportsArtifacts: true,
  }),

  createModelConfig("mistral-nemo", PROVIDER, {
    name: "Mistral Nemo",
    matchingModel: "open-mistral-nemo",
    description:
      "Trained jointly by Mistral AI and NVIDIA, it significantly outperforms existing models smaller or similar in size.",
    type: ["text"],
    supportsFunctions: true,
    isFree: true,
    card: "https://www.prompthub.us/models/mistral-nemo",
    contextWindow: 128000,
    maxTokens: 128000,
    costPer1kInputTokens: 0.002,
    costPer1kOutputTokens: 0.006,
    strengths: [
      "chat",
      "general_knowledge",
      "analysis",
      "creative",
      "multilingual",
    ],
    contextComplexity: 3,
    reliability: 3,
    speed: 4,
    isFeatured: true,
    includedInRouter: true,
  }),

  createModelConfig("pixtral-large", PROVIDER, {
    name: "Pixtral Large",
    matchingModel: "pixtral-large-latest",
    type: ["image-to-text"],
    supportsFunctions: true,
    card: "https://www.prompthub.us/models/pixtral",
    contextWindow: 128000,
    maxTokens: 128000,
    costPer1kInputTokens: 0.002,
    costPer1kOutputTokens: 0.006,
    strengths: ["vision", "multilingual"],
    contextComplexity: 4,
    reliability: 4,
    speed: 3,
    isFree: true,
    isFeatured: true,
    includedInRouter: true,
  }),

  createModelConfig("codestral", PROVIDER, {
    name: "Codestral",
    matchingModel: "codestral-latest",
    description:
      "Codestral is Mistral AI's first-ever code model designed for code generation tasks.",
    type: ["coding"],
    isFree: true,
    card: "https://www.prompthub.us/models/codestral",
    contextWindow: 256000,
    maxTokens: 256000,
    costPer1kInputTokens: 0.002,
    costPer1kOutputTokens: 0.006,
    strengths: ["coding", "multilingual"],
    contextComplexity: 4,
    reliability: 4,
    speed: 3,
    isFeatured: true,
    includedInRouter: true,
  }),
]);
