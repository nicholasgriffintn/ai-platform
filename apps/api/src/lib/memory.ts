import { AIProviderFactory } from "~/lib/providers/factory";
import type { IEnv, IUser, IUserSettings, Message } from "~/types";
import { generateId } from "~/utils/id";
import { parseAIResponseJson } from "~/utils/json";
import { AssistantError, ErrorType } from "~/utils/errors";
import { getLogger } from "~/utils/logger";
import type { ConversationManager } from "./conversationManager";
import { Embedding } from "./embedding";
import { getAuxiliaryModel } from "./models";
import { MemoryRepository } from "~/repositories/MemoryRepository";

const logger = getLogger({ prefix: "lib/memory" });

export interface MemoryEvent {
  type: "store" | "snapshot";
  text: string;
  category: string;
}

export class MemoryManager {
  private env: IEnv;
  private user?: IUser;

  constructor(env: IEnv, user?: IUser) {
    this.env = env;
    this.user = user;
  }

  public static getInstance(env: IEnv, user?: IUser): MemoryManager {
    return new MemoryManager(env, user);
  }

  /**
   * Store a short summary or snippet into the memory vector store under a dedicated namespace
   * @param metadata arbitrary string-based metadata (e.g. conversationId, timestamp, category)
   * @param conversationId optional conversation ID to link this memory to
   */
  public async storeMemory(
    text: string,
    metadata: Record<string, string>,
    conversationId?: string,
  ): Promise<string | null> {
    const embedding = Embedding.getInstance(this.env, this.user);
    const vectorId = generateId();

    logger.debug("Storing memory", { text, metadata, vectorId });

    const vectors = await embedding.generate("memory", text, vectorId, {
      ...metadata,
      text,
      stored_at: Date.now().toString(),
    });

    const namespace = `memory_user_${this.user?.id ?? "global"}`;

    const rawVec = vectors[0].values as number[];
    const candidateVector = new Float64Array(rawVec);
    const existing = await embedding.getMatches(candidateVector, {
      topK: 5,
      scoreThreshold: 0,
      namespace,
      returnMetadata: "all",
    });

    const similarMemories = (existing.matches || [])
      .filter((m) => m.score >= 0.85 && m.metadata?.text)
      .map((m) => ({
        text: m.metadata.text as string,
        score: m.score,
        id: m.id,
      }));

    if (similarMemories.length > 0) {
      logger.debug("Found similar memories, skipping insertion", {
        similarMemories,
      });
      return null;
    }

    logger.debug("Inserting memory", {
      vectorCount: vectors.length,
      namespace,
      category: metadata.category,
    });

    await embedding.insert(vectors, { namespace });

    if (this.user?.id) {
      try {
        const repository = new MemoryRepository(this.env);
        const memoryRecord = await repository.createMemory(
          this.user.id,
          text,
          metadata.category || "general",
          vectorId,
          conversationId,
          {
            ...metadata,
            stored_at: Date.now().toString(),
          },
        );
        return memoryRecord?.id || null;
      } catch (error) {
        logger.warn("Failed to store memory in transactional database", {
          error,
        });
      }
    }

    return null;
  }

  /**
   * Delete a memory from both vector and transactional databases
   * @param memoryId - The memory ID from the transactional database
   */
  public async deleteMemory(memoryId: string): Promise<boolean> {
    if (!this.user?.id) {
      throw new AssistantError(
        "User ID is required to delete memories",
        ErrorType.AUTHENTICATION_ERROR,
      );
    }

    const repository = new MemoryRepository(this.env);
    const memory = await repository.getMemoryById(memoryId);

    if (!memory || memory.user_id !== this.user.id) {
      logger.warn("Memory not found or access denied", {
        memoryId,
        userId: this.user.id,
      });
      return false;
    }

    try {
      if (memory.vector_id) {
        const embedding = Embedding.getInstance(this.env, this.user);
        await embedding.delete([memory.vector_id]);
      }

      await repository.deleteMemory(memoryId);

      await repository.removeMemoryFromGroups(memoryId);

      logger.debug("Memory deleted successfully", {
        memoryId,
        vectorId: memory.vector_id,
      });
      return true;
    } catch (error) {
      logger.error("Failed to delete memory", { error, memoryId });
      return false;
    }
  }

  /**
   * Retrieve top‚Äêk memories most relevant to a text query
   * @param query - The text query to retrieve memories for
   * @param opts - Optional parameters for the retrieval
   * @returns An array of memories with their scores
   */
  public async retrieveMemories(
    query: string,
    opts?: { topK?: number; scoreThreshold?: number },
  ): Promise<Array<{ text: string; score: number }>> {
    const embedding = Embedding.getInstance(this.env, this.user);
    const topK = opts?.topK ?? 3;
    const scoreThreshold = opts?.scoreThreshold ?? 0.3;
    const namespace = `memory_user_${this.user?.id ?? "global"}`;

    logger.debug("Memory query", { query });

    const queryEmb = await embedding.getQuery(query);
    const rawNumbers = queryEmb.data[0] as number[];
    const vector = new Float64Array(rawNumbers);

    const result = await embedding.getMatches(vector, {
      topK: Math.max(topK * 2, 10),
      scoreThreshold,
      namespace,
      returnMetadata: "all",
    });

    logger.debug("Raw memory matches", {
      matches: result.matches?.length || 0,
    });

    if (!result.matches) {
      logger.debug("Insufficient matches.");

      return [];
    }

    const memories = (result.matches || [])
      .filter(
        (m) =>
          m.score >= scoreThreshold && typeof m.metadata?.text === "string",
      )
      .slice(0, topK)
      .map((m) => ({ text: m.metadata.text as string, score: m.score }));

    logger.debug("Retrieved memories", {
      count: memories.length,
      topScore: memories[0]?.score,
    });

    return memories;
  }

  /**
   * Process a user turn: classify the last user message, store key memories, and take periodic snapshots.
   * @param lastUser - The last user message
   * @param messages - The messages in the conversation
   * @param conversationManager - The conversation manager
   * @param completionId - The ID of the completion
   * @param userSettings - The user settings
   * @returns An array of memory events
   */
  public async handleMemory(
    lastUser: string,
    messages: Message[],
    conversationManager: ConversationManager,
    completionId: string,
    userSettings: IUserSettings,
  ): Promise<MemoryEvent[]> {
    const events: MemoryEvent[] = [];

    if (userSettings?.memories_save_enabled) {
      try {
        if (lastUser.trim()) {
          const { model: modelToUse, provider: providerToUse } =
            await getAuxiliaryModel(this.env, this.user);
          const provider = AIProviderFactory.getProvider(providerToUse);
          const classifier = await provider.getResponse(
            {
              model: modelToUse,
              env: this.env,
              user: this.user,
              messages: [
                {
                  role: "system",
                  content: `You are a memory classifier for an AI assistant. Analyze the following user message and determine if it contains information worth remembering as a long-term memory. This could include facts about the user, preferences, important events, appointments, goals, or other significant information. 

For memories that should be stored, provide a clear, concise summary that will be easily retrievable when the user asks related questions later. 

IMPORTANT: Convert any relative dates to absolute dates. Today's date is ${new Date().toLocaleDateString("en-US", { weekday: "long", year: "numeric", month: "long", day: "numeric" })}.

EXAMPLES:

Input: "I love Italian food"
Output: { "storeMemory": true, "category": "preference", "summary": "User loves Italian food" }

Input: "My green sofa is arriving tomorrow"
Output: { "storeMemory": true, "category": "schedule", "summary": "User's green sofa is arriving on ${new Date(Date.now() + 24 * 60 * 60 * 1000).toLocaleDateString()}" }

Input: "I work at Google as a software engineer"
Output: { "storeMemory": true, "category": "fact", "summary": "User works at Google as a software engineer" }

Input: "My goal is to learn Spanish this year"
Output: { "storeMemory": true, "category": "goal", "summary": "User's goal is to learn Spanish in ${new Date().getFullYear()}" }

Input: "I have a doctor appointment next Friday at 3pm"
Output: { "storeMemory": true, "category": "schedule", "summary": "User has a doctor appointment on [next Friday's actual date] at 3pm" }

Input: "What's the weather like?"
Output: { "storeMemory": false, "category": "", "summary": "" }

Input: "Thanks for helping me"
Output: { "storeMemory": false, "category": "", "summary": "" }

Respond with JSON: { storeMemory: boolean, category: string, summary: string }. Use specific categories: 'preference', 'schedule', 'goal', 'fact', 'opinion'.`,
                },
                { role: "user", content: lastUser },
              ],
              response_format: { format: "json" },
            },
            this.user?.id,
          );

          const parsed = parseAIResponseJson<{
            storeMemory: boolean;
            category: string;
            summary: string;
          }>(classifier.response);

          if (parsed.data?.storeMemory) {
            const summaryText = parsed.data.summary || lastUser;
            const category = parsed.data.category || "general";

            logger.debug("Storing classified memory", {
              summaryText,
              category,
            });

            await this.storeMemory(summaryText, {
              conversationId: completionId,
              timestamp: Date.now().toString(),
              category,
              isNormalized: "false",
            });

            if (["fact", "schedule", "preference"].includes(category)) {
              try {
                const normalizer = await provider.getResponse(
                  {
                    model: modelToUse,
                    env: this.env,
                    user: this.user,
                    messages: [
                      {
                        role: "system",
                        content:
                          "You are a memory normalizer. Transform the following user information into 1-2 concise, factual statements that capture the same information but with different wording. Focus on creating clear, declarative statements (NOT questions) that would help with semantic search matching. Each alternative should be a plain, factual sentence. Maintain any specific dates that are mentioned - do not convert them back to relative terms. Respond with a JSON array of strings. Avoid creating questions or redundant phrasings.",
                      },
                      { role: "user", content: summaryText },
                    ],
                    response_format: { format: "json" },
                  },
                  this.user?.id,
                );

                try {
                  let normalized: string[] = [];
                  const response = normalizer.response?.trim() || "";

                  const parsedResponse = parseAIResponseJson<
                    string[] | { text: string[] }
                  >(response);

                  if (parsedResponse) {
                    if (Array.isArray(parsedResponse.data)) {
                      normalized = parsedResponse.data;
                    } else if (
                      parsedResponse.data?.text &&
                      Array.isArray(parsedResponse.data.text)
                    ) {
                      normalized = parsedResponse.data.text;
                    }
                  }

                  normalized = normalized
                    .filter(
                      (text) =>
                        typeof text === "string" && text.trim().length > 0,
                    )
                    .map((text) => text.trim())
                    .filter(
                      (text) =>
                        !text.includes("###") &&
                        !text.includes("**") &&
                        text.length < 200,
                    );

                  for (const altText of normalized) {
                    await this.storeMemory(altText, {
                      conversationId: completionId,
                      timestamp: Date.now().toString(),
                      category,
                      isNormalized: "true",
                      originalText: summaryText,
                    });
                    logger.debug("Stored alternative memory phrasing", {
                      altText,
                    });
                  }
                } catch (e) {
                  logger.debug("Failed to process normalized memory", {
                    error: e,
                    response: normalizer.response,
                  });
                }
              } catch (e) {
                logger.debug("Failed to normalize memory", { error: e });
              }
            }

            events.push({ type: "store", text: summaryText, category });
          }
        }
      } catch (e) {
        logger.debug("Memory classification failed", { error: e });
      }
    }

    if (userSettings?.memories_chat_history_enabled) {
      try {
        const userCount = messages.filter((m) => m.role === "user").length;
        if (userCount > 0 && userCount % 5 === 0) {
          const recent = await conversationManager.get(
            completionId,
            undefined,
            10,
          );
          const snippet = recent
            .map(
              (m) =>
                `${m.role}: ${typeof m.content === "string" ? m.content : JSON.stringify(m.content)}`,
            )
            .join("\n");
          logger.debug("Summarizing conversation", { snippet });
          const { model: modelToUse, provider: providerToUse } =
            await getAuxiliaryModel(this.env, this.user);
          const provider = AIProviderFactory.getProvider(providerToUse);
          const summaryResp = await provider.getResponse(
            {
              model: modelToUse,
              env: this.env,
              user: this.user,
              messages: [
                {
                  role: "system",
                  content:
                    "You are a memory summarizer. Summarize the following conversation snippet into a single short memory capturing any important facts, preferences, goals, or events.",
                },
                { role: "user", content: snippet },
              ],
            },
            this.user?.id,
          );
          const text = summaryResp.response?.trim();
          if (text) {
            const category = "snapshot";
            logger.debug("Storing snapshot", { text });
            try {
              await this.storeMemory(text, {
                conversationId: completionId,
                timestamp: Date.now().toString(),
                category,
              });
              events.push({ type: "snapshot", text, category });
            } catch (e) {
              logger.debug("Failed to store snapshot", { error: e });
            }
          }
        }
      } catch (e) {
        logger.debug("Snapshot generation failed", { error: e });
      }
    }

    return events;
  }
}
