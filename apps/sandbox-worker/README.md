# Sandbox Worker

An automated coding tool that uses Cloudflare Sandboxes within a Worker environment to allow AI models to complete tasks against GitHub repositories. The worker clones a repo, generates an implementation plan, runs an iterative agent loop inside the sandbox, runs a quality gate, tracks PRD story progress, and can commit changes back to GitHub.

> [!NOTE]
> This is an initial implementation to explore Cloudflare Sandbox capabilities. It demonstrates the core workflow but isn't feature-complete yet.

## Overview

Cloudflare Sandbox provides the ability to build isolated code execution environments within the Cloudflare Worker platform. This implementation uses the SDK that Cloudflare provides to run isolated shell commands that have been generated by the main Polychat AI on the Cloudflare Containers environment.

Containers are completely serverless and can run code that has been written in a range of programming languages and for any runtime all within the same Cloudflare environment.

This allows for resource intensive tasks, workloads that require a full filesystem and in this case, the ability to run commands against an unknown codebase and with AI generated commands without having to worry about the security implications of running untrusted code within the main application.

As it is serverless, this can also be done at a larger scale and with increased demand vs what our main API can handle.

The current implementation focuses on just one task, feature implementation, but it has been designed to be extended for more task types in the future.

Here's the current workflow:

1. **GitHub Integration** - Users install a GitHub App, then trigger tasks via `/implement {task}` PR comments, the main API handles the authentication and sends a request to this worker via the service binding. It will also receive webhook events from GitHub.
2. **Repository Context + AI Planning** - The worker inspects repository structure, loads key files (including PRD files such as `prd.json` or `tasks/prd-*.md`), and asks the model to create an implementation plan with explicit validation commands.
3. **Agentic Isolated Execution** - An iterative loop runs in a Cloudflare Container sandbox. The agent can run a command, read files for more context, refine its plan, and finish only when done or blocked.
4. **Quality Gate** - After implementation, the worker derives validation commands from the plan and runs them as a post-implementation gate.
5. **Story Tracking** - For `prd.json` workflows, the worker selects the implemented story, updates `passes` based on quality-gate results, and appends a run entry to `progress.txt`.
6. **Git Operations** - Changes can be committed to a feature branch for PR review using the Sandbox SDK. Commits are skipped when the quality gate fails.
7. **Real-time Progress** - SSE events stream execution progress to the UI

## Configuration

### Environment Variables

| Variable             | Description                                                  |
| -------------------- | ------------------------------------------------------------ |
| `SANDBOX_JWT_SECRET` | Secret for JWT token verification, this should match the API |

## API Endpoint

### POST /execute

Execute a feature implementation task.

**Headers:**

- `Authorization: Bearer <jwt>` - JWT token with user context
- `X-GitHub-Token: <token>` - GitHub installation access token

**Body:**

```json
{
	"task": "feature-implementation",
	"params": {
		"repo": "owner/repo",
		"task": "Add a logout button to the navbar",
		"model": "mistral-large",
		"promptStrategy": "auto",
		"shouldCommit": true
	}
}
```

**Response:** SSE stream with execution events.

## Development

```bash
# Install dependencies
pnpm install

# Start local development
pnpm run dev

# Deploy to Cloudflare
pnpm run deploy
```

## Known Limitations (that we plan to address in future iterations)

- Commands only (no Python scripts, interactive tools)
- Command isolation (no chaining with `&&`, pipes)
- Shallow clone only (full history not available)
- Log truncation at 80,000 characters
- No code interpreter support

## Roadmap - Generated with AI Assistance

This section outlines planned improvements to make the sandbox worker production-ready.

### Phase 1: Agent-based Execution

**Current limitation:** Initial implementation is complete, but the loop still supports a single task family (`feature-implementation`).

**Planned improvements:**

- [x] Implement agentic loop that can react to command outputs using the existing agents setup for the API (extended as required for the sandbox context but maintainable and consistent with the main API)
- [x] Add multi-step reasoning where the agent can:
  - Run a command and inspect output
  - Decide next action based on results
  - Handle errors and retry with different approaches
  - Request additional context when needed
- [x] Support iterative refinement of implementation plan
- [x] Add ability to read file contents mid-execution for context
- [x] Add a post-implementation quality gate that runs validation commands from the plan
- [x] Gate commits on quality-gate outcomes

### Phase 2: Enhanced Prompting

**Current limitation:** Prompting is now context-aware, but it still needs richer task-specific examples/strategy variants.

**Planned improvements:**

- [x] Analyse repository structure before planning (package.json, config files)
- [x] Include relevant code snippets in context
- [x] Support for PRD-style task files (`prd.json`, `tasks/prd-*.md`) for repo-specific instructions (with `.implement` fallback)
- [x] Track PRD story progress by updating `prd.json` `passes` and logging to `progress.txt`
- [x] Add examples of good implementations for the model to follow
- [x] Support different prompt strategies per task type

### Phase 3: Error Handling and Resilience

**Current limitation:** Error handling is now structured for runs, but outbound notifications still need expansion.

**Planned improvements:**

- [x] Comprehensive error classification and user-friendly messages
- [x] Retry logic for transient failures (network, rate limits)
- [x] Graceful degradation when AI model unavailable
- [x] Detailed error logging with context for debugging

### Phase 4: UI and UX Improvements

**Current limitation:** Basic implementation, not a conversational interface.

**Planned improvements:**

- [ ] Reuse existing chat UI components for continuous conversation flow
- [ ] Allow user to provide feedback mid-execution
- [ ] Show AI reasoning alongside command execution
- [ ] Add ability to approve/reject individual commands before execution
- [x] Implement run cancellation from client (abort SSE stream and sandbox)
- [ ] Better diff viewer with syntax highlighting

### Phase 5: Stream and Execution Control

**Current limitation:** Core execution controls are now implemented; remaining work is production hardening and observability.

**Planned improvements:**

- [x] Implement cancellation signal from client to API to worker
- [x] Add timeout configuration per task
- [x] Support pause/resume for long-running tasks
- [x] Add execution quotas and rate limiting per user

### Phase 6: Webhook Expansion

**Current status:** Handles `/implement`, `/review`, `/test`, and `/fix` commands from issue and PR comments.

**Planned improvements:**

- [x] Support issue comments (not just PRs)
- [x] Add `/review` command for code review
- [x] Add `/test` command to run test suites
- [x] Add `/fix` command for automated bug fixes

### Phase 7: Storage and Observability

**Current limitation:** Logs stored inline, not suitable for high volumes.

**Planned improvements:**

- [ ] Store full execution logs in R2 with presigned URLs
- [ ] Implement log retention policies (configurable per user/org)
- [ ] Add user controls for log storage (auto-delete, archive)
- [ ] Add execution metrics and dashboards
- [ ] Support log streaming to external systems

### Phase 8: Expanded Task Types

**Current status:** Supports feature implementation, code review, test suite, bug fix, refactoring, documentation, and migration task modes.

**Planned improvements:**

- [x] **Code Review** - Automated PR reviews with actionable feedback
- [x] **Bug Fix** - Diagnose and fix issues from error reports
- [x] **Refactoring** - Apply consistent code improvements
- [x] **Documentation** - Generate/update docs from code
- [x] **Testing** - Generate test cases for existing code
- [x] **Migration** - Automated dependency/framework upgrades
